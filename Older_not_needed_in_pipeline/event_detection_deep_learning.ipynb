{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import creep_event_picker as cep\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('../../Data/DATA_tidied/CSV/xhr2.csv', parse_dates=['Time'])\n",
    "\n",
    "# Assuming 'Time' is the timestamp column and 'Slip' is the value column\n",
    "time = pd.to_datetime(data['Time'])\n",
    "slip = data['Slip']\n",
    "\n",
    "# Upsample the data to 1-minute intervals using cep.interpolate\n",
    "tm_int, slip_int, upsampled = cep.interpolate(time, slip, 10)  # 1-minute interval\n",
    "\n",
    "sos = scipy.signal.butter(4,[1/7200,1/120], 'band',output = 'sos',fs=0.10) #bandpass filter for 2hrs and 5days\n",
    "creep_data  = scipy.signal.sosfiltfilt(sos,slip_int) # filter the data\n",
    "time_series_data = pd.Series(creep_data, index=pd.to_datetime(tm_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_catalogue = pd.read_csv('../../Data/all_creep_event_picks_new_qc_Oct_02_2024.csv',index_col=0)\n",
    "event_catalogue.drop(event_catalogue[event_catalogue['Creepmeter_abbrv']!='XHR2'].index,inplace=True)\n",
    "event_catalogue.reset_index(inplace=True,drop=True)\n",
    "event_catalogue['start_time'] = pd.to_datetime(event_catalogue['ST'])\n",
    "event_catalogue['end_time'] = pd.to_datetime(event_catalogue['ET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        value  label\n",
      "1991-11-24 00:00:00 -0.009379      0\n",
      "1991-11-24 00:10:00 -0.015654      0\n",
      "1991-11-24 00:20:00 -0.021321      0\n",
      "1991-11-24 00:30:00 -0.025900      0\n",
      "1991-11-24 00:40:00 -0.029126      0\n"
     ]
    }
   ],
   "source": [
    "# Assuming `time_series_data` is a Pandas Series with the time series values\n",
    "# and `event_catalogue` is a DataFrame with the event start and end times\n",
    "\n",
    "# Initialize a labels array with zeros\n",
    "labels = np.zeros(len(time_series_data), dtype=int)\n",
    "\n",
    "# Label the data based on event start and end times\n",
    "for _, row in event_catalogue.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    \n",
    "    # Find the index positions for start and end times\n",
    "    start_index = time_series_data.index.searchsorted(start_time, side='left')\n",
    "    end_index = time_series_data.index.searchsorted(end_time, side='right') - 1\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    start_index = min(start_index, len(time_series_data) - 1)\n",
    "    end_index = min(end_index, len(time_series_data) - 1)\n",
    "    \n",
    "    # Label the range between start and end indices\n",
    "    if start_index <= end_index:\n",
    "        labels[start_index:end_index + 1] = 1  # +1 to include the end index\n",
    "\n",
    "# Combine into a DataFrame if needed\n",
    "data_with_labels = pd.DataFrame({\n",
    "    'value': time_series_data,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Optional: Display the first few rows of the labeled data\n",
    "print(data_with_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_36808/1380143963.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_with_labels.fillna(method='bfill', inplace=True)  # Backfill NaNs\n",
      "/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_36808/1380143963.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_with_labels.fillna(method='ffill', inplace=True)  # Forward fill if needed\n"
     ]
    }
   ],
   "source": [
    "# Assume 'data_with_labels' is your DataFrame with 'value' and 'label' columns\n",
    "\n",
    "# Create rolling features\n",
    "data_with_labels['rolling_mean'] = data_with_labels['value'].rolling(window=60).mean()  # Mean over the last hour\n",
    "data_with_labels['rolling_std'] = data_with_labels['value'].rolling(window=60).std()   # Std over the last hour\n",
    "\n",
    "# Create lag features\n",
    "data_with_labels['lag_1'] = data_with_labels['value'].shift(1)  # Previous value\n",
    "data_with_labels['lag_2'] = data_with_labels['value'].shift(2)  # Value from two time steps back\n",
    "\n",
    "# Cumulative features\n",
    "data_with_labels['cumulative_sum'] = data_with_labels['value'].cumsum()\n",
    "data_with_labels['cumulative_mean'] = data_with_labels['value'].expanding().mean()\n",
    "\n",
    "\n",
    "# Fill NaNs created by rolling or lag features\n",
    "data_with_labels.fillna(method='bfill', inplace=True)  # Backfill NaNs\n",
    "data_with_labels.fillna(method='ffill', inplace=True)  # Forward fill if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>rolling_std</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>cumulative_sum</th>\n",
       "      <th>cumulative_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-11-24 00:00:00</th>\n",
       "      <td>-0.009379</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>-0.009379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-11-24 00:10:00</th>\n",
       "      <td>-0.015654</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>-0.025034</td>\n",
       "      <td>-0.012517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-11-24 00:20:00</th>\n",
       "      <td>-0.021321</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>-0.046355</td>\n",
       "      <td>-0.015452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-11-24 00:30:00</th>\n",
       "      <td>-0.025900</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>-0.021321</td>\n",
       "      <td>-0.015654</td>\n",
       "      <td>-0.072254</td>\n",
       "      <td>-0.018064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-11-24 00:40:00</th>\n",
       "      <td>-0.029126</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028697</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>-0.021321</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>-0.020276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-26 23:40:00</th>\n",
       "      <td>0.004005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>-1.366874</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-26 23:50:00</th>\n",
       "      <td>0.003129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>-1.363744</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-27 00:00:00</th>\n",
       "      <td>0.001537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>-1.362208</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-27 00:10:00</th>\n",
       "      <td>-0.000644</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>-1.362851</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-27 00:20:00</th>\n",
       "      <td>-0.003155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>-1.366006</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714819 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value  label  rolling_mean  rolling_std     lag_1  \\\n",
       "1991-11-24 00:00:00 -0.009379      0     -0.028697     0.003331 -0.009379   \n",
       "1991-11-24 00:10:00 -0.015654      0     -0.028697     0.003331 -0.009379   \n",
       "1991-11-24 00:20:00 -0.021321      0     -0.028697     0.003331 -0.015654   \n",
       "1991-11-24 00:30:00 -0.025900      0     -0.028697     0.003331 -0.021321   \n",
       "1991-11-24 00:40:00 -0.029126      0     -0.028697     0.003331 -0.025900   \n",
       "...                       ...    ...           ...          ...       ...   \n",
       "2005-06-26 23:40:00  0.004005      0      0.000900     0.006366  0.004169   \n",
       "2005-06-26 23:50:00  0.003129      0      0.000808     0.006291  0.004005   \n",
       "2005-06-27 00:00:00  0.001537      0      0.000683     0.006199  0.003129   \n",
       "2005-06-27 00:10:00 -0.000644      0      0.000514     0.006092  0.001537   \n",
       "2005-06-27 00:20:00 -0.003155      0      0.000292     0.005977 -0.000644   \n",
       "\n",
       "                        lag_2  cumulative_sum  cumulative_mean  \n",
       "1991-11-24 00:00:00 -0.009379       -0.009379        -0.009379  \n",
       "1991-11-24 00:10:00 -0.009379       -0.025034        -0.012517  \n",
       "1991-11-24 00:20:00 -0.009379       -0.046355        -0.015452  \n",
       "1991-11-24 00:30:00 -0.015654       -0.072254        -0.018064  \n",
       "1991-11-24 00:40:00 -0.021321       -0.101381        -0.020276  \n",
       "...                       ...             ...              ...  \n",
       "2005-06-26 23:40:00  0.003741       -1.366874        -0.000002  \n",
       "2005-06-26 23:50:00  0.004169       -1.363744        -0.000002  \n",
       "2005-06-27 00:00:00  0.004005       -1.362208        -0.000002  \n",
       "2005-06-27 00:10:00  0.003129       -1.362851        -0.000002  \n",
       "2005-06-27 00:20:00  0.001537       -1.366006        -0.000002  \n",
       "\n",
       "[714819 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Step 1: Define features and target\n",
    "X = data_with_labels.drop(columns=['value', 'label'])\n",
    "y = data_with_labels['label']\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 3: Reshape the data for LSTM\n",
    "# Assuming your data has a single timestep, adjust if necessary\n",
    "X_train_reshaped = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Step 4: Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class classification\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del event_catalogue, creep_data,tm_int,slip_int,slip, time, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating windows: 100%|██████████| 7146742/7146742 [00:45<00:00, 157531.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (7146742, 1440)\n",
      "Shape of y: (7146742,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_windows(data, labels, window_size):\n",
    "    # Ensure the data and labels are numpy arrays\n",
    "    data = data.values  # Convert to numpy array if it's not already\n",
    "    labels = labels.values  # Convert to numpy array if it's not already\n",
    "\n",
    "    # Calculate the number of windows\n",
    "    num_windows = len(data) - window_size + 1\n",
    "\n",
    "    # Create 3D array for the windows\n",
    "    X = np.empty((num_windows, window_size))  # Pre-allocate memory for efficiency\n",
    "\n",
    "    # Use tqdm to display progress\n",
    "    for i in tqdm(range(num_windows), desc=\"Creating windows\"):\n",
    "        X[i] = data[i:i + window_size]  # Fill the window\n",
    "\n",
    "    # Create labels for each window using the last label in each window\n",
    "    y = labels[window_size - 1:]  # Get labels for the last point in each window\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Define your window size (e.g., 1440 for 1 day if data is at 1-minute intervals)\n",
    "window_size = 1440  # Change as needed\n",
    "\n",
    "# Create windows of data\n",
    "X, y = create_windows(data_with_labels['value'], data_with_labels['label'], window_size)\n",
    "\n",
    "# Check the shape of the output\n",
    "print(\"Shape of X:\", X.shape)  # Should be (num_samples, window_size)\n",
    "print(\"Shape of y:\", y.shape)  # Should be (num_samples,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_36432/3485664322.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_with_labels.fillna(method='bfill', inplace=True)  # Backfill NaNs\n",
      "/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_36432/3485664322.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data_with_labels.fillna(method='ffill', inplace=True)  # Forward fill if needed\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to be 3D for LSTM (samples, time steps, features)\n",
    "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))  # Assuming 1 feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (570704, 1440, 1)\n",
      "Testing data shape: (142676, 1440, 1)\n",
      "Training labels shape: (570704,)\n",
      "Testing labels shape: (142676,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Check the shapes of the resulting datasets\n",
    "print(\"Training data shape:\", X_train.shape)  # Should be (num_samples_train, window_size, 1)\n",
    "print(\"Testing data shape:\", X_test.shape)    # Should be (num_samples_test, window_size, 1)\n",
    "print(\"Training labels shape:\", y_train.shape)  # Should match num_samples_train\n",
    "print(\"Testing labels shape:\", y_test.shape)    # Should match num_samples_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Add LSTM layer\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))  # 50 units, returns sequences for the next layer\n",
    "model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "\n",
    "# Add a second LSTM layer\n",
    "model.add(LSTM(50, return_sequences=False))  # Last LSTM layer does not return sequences\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepmeters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
