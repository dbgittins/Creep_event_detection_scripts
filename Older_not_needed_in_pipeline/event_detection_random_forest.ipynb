{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import creep_event_picker as cep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        value  label\n",
      "1991-11-24 00:00:00 -0.007280      0\n",
      "1991-11-24 00:10:00 -0.000823      0\n",
      "1991-11-24 00:20:00  0.004949      0\n",
      "1991-11-24 00:30:00  0.009505      0\n",
      "1991-11-24 00:40:00  0.012568      0\n",
      "...                       ...    ...\n",
      "2020-08-28 06:00:00  0.012500      0\n",
      "2020-08-28 06:10:00  0.011360      0\n",
      "2020-08-28 06:20:00  0.009665      0\n",
      "2020-08-28 06:30:00  0.007517      0\n",
      "2020-08-28 06:40:00  0.005115      0\n",
      "\n",
      "[1512761 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the HDF5 data\n",
    "with h5py.File('../../Data/DATA_tidied/HDF5/CWN1.h5', 'r') as hdf:\n",
    "    # Access a specific dataset\n",
    "    dataset = hdf['CWN1_10.0mins']\n",
    "    slip = dataset['Slip_CWN1_10.0mins'][:]\n",
    "    time = dataset['Time_CWN1_10.0mins'][:]\n",
    "    \n",
    "    # Decode the time data\n",
    "    decoded_time = [byte_str.decode('utf-8') for byte_str in time]\n",
    "    decoded_time = pd.to_datetime(decoded_time)\n",
    "\n",
    "    # Interpolate data\n",
    "    tm_int, creep_int, upsampled = cep.interpolate(decoded_time, slip, 10)\n",
    "    sos = scipy.signal.butter(4,[1/7200,1/120], 'band',output = 'sos',fs=0.10) #bandpass filter for 2hrs and 5days\n",
    "    creep_data  = scipy.signal.sosfiltfilt(sos,creep_int) # filter the data\n",
    "    time_series_data = pd.Series(creep_data, index=pd.to_datetime(tm_int))\n",
    "\n",
    "# Load the event catalogue\n",
    "event_catalogue = pd.read_csv('../../Data/all_creep_event_picks_new_qc_Oct_02_2024.csv',index_col=0)\n",
    "event_catalogue.drop(event_catalogue[event_catalogue['Creepmeter_abbrv']!='CWN1'].index,inplace=True)\n",
    "event_catalogue.drop(event_catalogue[event_catalogue['File_code']!='cwn_0'].index,inplace=True)\n",
    "event_catalogue.reset_index(inplace=True,drop=True)\n",
    "event_catalogue['start_time'] = pd.to_datetime(event_catalogue['ST'])\n",
    "event_catalogue['end_time'] = pd.to_datetime(event_catalogue['ET'])\n",
    "event_catalogue\n",
    "\n",
    "# Initialize a labels array with zeros\n",
    "labels = np.zeros(len(time_series_data), dtype=int)\n",
    "\n",
    "# Label the data based on event start and end times\n",
    "for _, row in event_catalogue.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    \n",
    "    # Find the start index for the event\n",
    "    start_index = time_series_data.index.searchsorted(start_time, side='left')\n",
    "    # Find the end index for the event (add one to include the last point in the event)\n",
    "    end_index = time_series_data.index.searchsorted(end_time, side='right') - 1\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    start_index = min(start_index, len(time_series_data) - 1)\n",
    "    end_index = min(end_index, len(time_series_data) - 1)\n",
    "    \n",
    "    # Label the range between start and end indices\n",
    "    if start_index <= end_index:\n",
    "        labels[start_index:end_index + 1] = 1  # +1 to include the end index\n",
    "\n",
    "# Combine into a DataFrame if needed\n",
    "data_with_labels = pd.DataFrame({\n",
    "    'value': time_series_data,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Optional: Display the first few rows of the labeled data\n",
    "print(data_with_labels)  # Display more rows for better context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 251455/1512330 [05:17<26:34, 790.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m432\u001b[39m  \u001b[38;5;66;03m# Example: 3 days worth of data\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_with_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_with_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Optionally, standardize the features\u001b[39;00m\n\u001b[1;32m     69\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(time_series, labels, window_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m q25 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(window, \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     46\u001b[0m q75 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(window, \u001b[38;5;241m75\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m rms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m))  \u001b[38;5;66;03m# Root Mean Square\u001b[39;00m\n\u001b[1;32m     48\u001b[0m skewness \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mskew(window)  \u001b[38;5;66;03m# Skewness\u001b[39;00m\n\u001b[1;32m     49\u001b[0m kurtosis \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mkurtosis(window)  \u001b[38;5;66;03m# Kurtosis\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/core/arraylike.py:242\u001b[0m, in \u001b[0;36mOpsMixin.__pow__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pow__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__pow__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/core/series.py:5819\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5818\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/core/base.py:1383\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/core/series.py:5915\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   5912\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   5914\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 5915\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5916\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5918\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   5919\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/core/series.py:514\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m--> 514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m \u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.data_manager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    516\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleBlockManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/_config/config.py:272\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/_config/config.py:149\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    146\u001b[0m key \u001b[38;5;241m=\u001b[39m _get_single_key(pat, silent)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m root, k \u001b[38;5;241m=\u001b[39m \u001b[43m_get_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m root[k]\n",
      "File \u001b[0;32m~/miniconda3/envs/creepmeters/lib/python3.10/site-packages/pandas/_config/config.py:637\u001b[0m, in \u001b[0;36m_get_root\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    635\u001b[0m cursor \u001b[38;5;241m=\u001b[39m _global_config\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 637\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m cursor[p]\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cursor, path[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''def extract_features(time_series, labels, window_size):\n",
    "    features = []\n",
    "    extracted_labels = []\n",
    "\n",
    "    # Iterate through the time series data using a sliding window\n",
    "    for i in range(len(time_series) - window_size + 1):\n",
    "        window = time_series[i:i + window_size]\n",
    "        \n",
    "        # Calculate features for the current window\n",
    "        mean = window.mean()\n",
    "        std = window.std()\n",
    "        min_val = window.min()\n",
    "        max_val = window.max()\n",
    "        median = window.median()\n",
    "        q25 = np.percentile(window, 25)\n",
    "        q75 = np.percentile(window, 75)\n",
    "        \n",
    "        features.append([mean, std, min_val, max_val, median, q25, q75])\n",
    "        \n",
    "        # Access labels using .iloc to avoid the FutureWarning\n",
    "        extracted_labels.append(labels.iloc[i + window_size - 1])  # Use the label for the last point in the window\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    features = np.array(features)\n",
    "    extracted_labels = np.array(extracted_labels)\n",
    "\n",
    "    return features, extracted_labels'''\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(time_series, labels, window_size):\n",
    "    features = []\n",
    "    extracted_labels = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for the loop\n",
    "    for i in tqdm(range(len(time_series) - window_size + 1), desc=\"Extracting features\"):\n",
    "        window = time_series[i:i + window_size]\n",
    "        \n",
    "        # Calculate features\n",
    "        mean = window.mean()\n",
    "        std = window.std()\n",
    "        min_val = window.min()\n",
    "        max_val = window.max()\n",
    "        median = window.median()\n",
    "        q25 = np.percentile(window, 25)\n",
    "        q75 = np.percentile(window, 75)\n",
    "        rms = np.sqrt(np.mean(window**2))  # Root Mean Square\n",
    "        skewness = scipy.stats.skew(window)  # Skewness\n",
    "        kurtosis = scipy.stats.kurtosis(window)  # Kurtosis\n",
    "        \n",
    "        features.append([mean, std, min_val, max_val, median, q25, q75, rms, skewness, kurtosis])\n",
    "        \n",
    "        extracted_labels.append(labels.iloc[i + window_size - 1])\n",
    "\n",
    "    features = np.array(features)\n",
    "    extracted_labels = np.array(extracted_labels)\n",
    "\n",
    "    return features, extracted_labels\n",
    "\n",
    "\n",
    "\n",
    "# Define window size\n",
    "window_size = 432  # Example: 3 days worth of data\n",
    "\n",
    "# Extract features\n",
    "X, y = extract_features(data_with_labels['value'], data_with_labels['label'], window_size)\n",
    "\n",
    "# Optionally, standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Combine features and labels into a DataFrame\n",
    "features_df = pd.DataFrame(X_scaled, columns=['mean', 'std', 'min', 'max', 'median', 'q25', 'q75'])\n",
    "features_df['label'] = y\n",
    "\n",
    "# Display the first few rows of the features DataFrame\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1209864 samples\n",
      "Testing set size: 302466 samples\n",
      "Random Forest model trained successfully.\n",
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    278386\n",
      "           1       1.00      1.00      1.00     24080\n",
      "\n",
      "    accuracy                           1.00    302466\n",
      "   macro avg       1.00      1.00      1.00    302466\n",
      "weighted avg       1.00      1.00      1.00    302466\n",
      "\n",
      "Confusion Matrix:\n",
      "[[278327     59]\n",
      " [    79  24001]]\n",
      "\n",
      "Custom Metrics Calculation:\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming X and y are already defined and the model has been trained\n",
    "\n",
    "# Step 2.4: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Print the sizes of the training and testing sets\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Step 3.5: Train a Random Forest Model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced',n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Random Forest model trained successfully.\")\n",
    "\n",
    "# Step 3.6: Evaluate the Model's Performance\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optionally, you can also display the individual metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\nCustom Metrics Calculation:\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_37379/2673877449.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_with_labels['predictions'][:len(y_pred)] = y_pred  # Assign predictions to the corresponding length\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.close('all')\n",
    "\n",
    "# Assuming 'data_with_labels' is your DataFrame with 'value', 'label', and 'predictions'\n",
    "data_with_labels['predictions'] = np.zeros(len(data_with_labels), dtype=int)  # Initialize with zeros\n",
    "data_with_labels['predictions'][:len(y_pred)] = y_pred  # Assign predictions to the corresponding length\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the entire time series in blue\n",
    "plt.plot(data_with_labels.index, data_with_labels['value'], color='blue', label='Creep Data', alpha=0.5)\n",
    "\n",
    "# Highlight the actual event times in red\n",
    "actual_event_times = data_with_labels.index[data_with_labels['label'] == 1]\n",
    "plt.scatter(actual_event_times, \n",
    "            data_with_labels['value'][data_with_labels['label'] == 1],\n",
    "            color='red', label='Actual Events', marker='o', s=50)  # Use markers for visibility\n",
    "\n",
    "# Highlight the predicted event times in green\n",
    "predicted_event_times = data_with_labels.index[data_with_labels['predictions'] == 1]\n",
    "plt.scatter(predicted_event_times, \n",
    "            data_with_labels['value'][data_with_labels['predictions'] == 1],\n",
    "            color='green', label='Predicted Events', marker='o', s=50,alpha=0.5)  # Use markers for visibility\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Creep Value')\n",
    "plt.title('Time Series with Highlighted Actual and Predicted Event Times')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/714388 [00:00<?, ?it/s]/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_37379/2430568094.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  extracted_labels.append(labels[i + window_size - 1])  # Use the label for the last point in the window\n",
      "Extracting features: 100%|██████████| 714388/714388 [14:47<00:00, 805.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean       std       min       max    median       q25       q75  \\\n",
      "0 -0.096964 -0.160655  0.159574 -0.182064  0.069596  0.219435 -0.152055   \n",
      "1 -0.095925 -0.160655  0.159574 -0.182064  0.070364  0.219712 -0.152055   \n",
      "2 -0.094396 -0.160723  0.159574 -0.182064  0.070919  0.219917 -0.152055   \n",
      "3 -0.092425 -0.160891  0.159574 -0.182064  0.070919  0.220217 -0.152055   \n",
      "4 -0.090097 -0.161166  0.159574 -0.182064  0.070919  0.220703 -0.152055   \n",
      "\n",
      "        rms  skewness  kurtosis  label  \n",
      "0 -0.170135 -1.682172  0.096769      0  \n",
      "1 -0.170174 -1.690388  0.104590      0  \n",
      "2 -0.170296 -1.704314  0.120952      0  \n",
      "3 -0.170529 -1.722608  0.145668      0  \n",
      "4 -0.170878 -1.743082  0.175753      0  \n",
      "Training set size: 571510 samples\n",
      "Testing set size: 142878 samples\n",
      "Random Forest model trained successfully.\n",
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    134771\n",
      "           1       1.00      1.00      1.00      8107\n",
      "\n",
      "    accuracy                           1.00    142878\n",
      "   macro avg       1.00      1.00      1.00    142878\n",
      "weighted avg       1.00      1.00      1.00    142878\n",
      "\n",
      "Confusion Matrix:\n",
      "[[134741     30]\n",
      " [    28   8079]]\n",
      "\n",
      "Custom Metrics Calculation:\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import creep_event_picker as cep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "\n",
    "# Load the HDF5 data\n",
    "with h5py.File('../../Data/DATA_tidied/HDF5/XHR2.h5', 'r') as hdf:\n",
    "    # Access a specific dataset\n",
    "    dataset = hdf['XHR2_10.0mins']\n",
    "    slip = dataset['Slip_XHR2_10.0mins'][:]\n",
    "    time = dataset['Time_XHR2_10.0mins'][:]\n",
    "    \n",
    "    # Decode the time data\n",
    "    decoded_time = [byte_str.decode('utf-8') for byte_str in time]\n",
    "    decoded_time = pd.to_datetime(decoded_time)\n",
    "\n",
    "    # Interpolate data\n",
    "    tm_int, creep_int, upsampled = cep.interpolate(decoded_time, slip, 10)\n",
    "    sos = scipy.signal.butter(4,[1/7200,1/120], 'band',output='sos',fs=0.10)  # bandpass filter for 2hrs and 5days\n",
    "    creep_data  = scipy.signal.sosfiltfilt(sos, creep_int)  # filter the data\n",
    "    time_series_data = pd.Series(creep_data, index=pd.to_datetime(tm_int))\n",
    "\n",
    "# Load the event catalogue\n",
    "event_catalogue = pd.read_csv('../../Data/all_creep_event_picks_new_qc_Oct_02_2024.csv', index_col=0)\n",
    "event_catalogue.drop(event_catalogue[event_catalogue['Creepmeter_abbrv'] != 'XHR2'].index, inplace=True)\n",
    "event_catalogue.reset_index(inplace=True, drop=True)\n",
    "event_catalogue['start_time'] = pd.to_datetime(event_catalogue['ST'])\n",
    "event_catalogue['end_time'] = pd.to_datetime(event_catalogue['ET'])\n",
    "\n",
    "# Initialize a labels array with zeros\n",
    "labels = np.zeros(len(time_series_data), dtype=int)\n",
    "\n",
    "# Label the data based on event start and end times\n",
    "for _, row in event_catalogue.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    \n",
    "    # Find the start index for the event\n",
    "    start_index = time_series_data.index.searchsorted(start_time, side='left')\n",
    "    # Find the end index for the event (add one to include the last point in the event)\n",
    "    end_index = time_series_data.index.searchsorted(end_time, side='right') - 1\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    start_index = min(start_index, len(time_series_data) - 1)\n",
    "    end_index = min(end_index, len(time_series_data) - 1)\n",
    "    \n",
    "    # Label the range between start and end indices\n",
    "    if start_index <= end_index:\n",
    "        labels[start_index:end_index + 1] = 1  # +1 to include the end index\n",
    "\n",
    "# Combine into a DataFrame if needed\n",
    "data_with_labels = pd.DataFrame({\n",
    "    'value': time_series_data,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Function to extract features with tqdm progress bar\n",
    "def extract_features(time_series, labels, window_size):\n",
    "    features = []\n",
    "    extracted_labels = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for the loop\n",
    "    for i in tqdm(range(len(time_series) - window_size + 1), desc=\"Extracting features\"):\n",
    "        window = time_series[i:i + window_size]\n",
    "        \n",
    "        # Calculate features\n",
    "        mean = window.mean()\n",
    "        std = window.std()\n",
    "        min_val = window.min()\n",
    "        max_val = window.max()\n",
    "        median = window.median()\n",
    "        q25 = np.percentile(window, 25)\n",
    "        q75 = np.percentile(window, 75)\n",
    "        rms = np.sqrt(np.mean(window**2))  # Root Mean Square\n",
    "        skewness = scipy.stats.skew(window)  # Skewness\n",
    "        kurtosis = scipy.stats.kurtosis(window)  # Kurtosis\n",
    "        \n",
    "        # Append all features to the list\n",
    "        features.append([mean, std, min_val, max_val, median, q25, q75, rms, skewness, kurtosis])\n",
    "        \n",
    "        # Access labels using .iloc to avoid the FutureWarning\n",
    "        extracted_labels.append(labels[i + window_size - 1])  # Use the label for the last point in the window\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    features = np.array(features)\n",
    "    extracted_labels = np.array(extracted_labels)\n",
    "\n",
    "    return features, extracted_labels\n",
    "\n",
    "# Define window size\n",
    "window_size = 432  # Example: 3 days worth of data\n",
    "\n",
    "# Extract features with a progress bar\n",
    "X, y = extract_features(data_with_labels['value'], data_with_labels['label'], window_size)\n",
    "\n",
    "# Optionally, standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Combine features and labels into a DataFrame\n",
    "features_df = pd.DataFrame(X_scaled, columns=['mean', 'std', 'min', 'max', 'median', 'q25', 'q75', 'rms', 'skewness', 'kurtosis'])\n",
    "features_df['label'] = y\n",
    "\n",
    "# Display the first few rows of the features DataFrame\n",
    "print(features_df.head())\n",
    "\n",
    "# Step 2.4: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Print the sizes of the training and testing sets\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Step 3.5: Train a Random Forest Model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Random Forest model trained successfully.\")\n",
    "\n",
    "# Step 3.6: Evaluate the Model's Performance\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optionally, you can also display the individual metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "TP = cm[1, 1]  # True Positives\n",
    "TN = cm[0, 0]  # True Negatives\n",
    "FP = cm[0, 1]  # False Positives\n",
    "FN = cm[1, 0]  # False Negatives\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\nCustom Metrics Calculation:\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 1.00\n",
      "Adjusted Precision: 1.00\n",
      "Adjusted Recall: 0.99\n",
      "Adjusted F1 Score: 0.99\n",
      "Adjusted Confusion Matrix:\n",
      "[[134757     14]\n",
      " [    71   8036]]\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust the threshold\n",
    "threshold = 0.7  # Change this value to your desired threshold\n",
    "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "accuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\n",
    "precision_adjusted = precision_score(y_test, y_pred_adjusted)\n",
    "recall_adjusted = recall_score(y_test, y_pred_adjusted)\n",
    "f1_score_adjusted = f1_score(y_test, y_pred_adjusted)\n",
    "confusion_matrix_adjusted = confusion_matrix(y_test, y_pred_adjusted)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Adjusted Accuracy: {accuracy_adjusted:.2f}\")\n",
    "print(f\"Adjusted Precision: {precision_adjusted:.2f}\")\n",
    "print(f\"Adjusted Recall: {recall_adjusted:.2f}\")\n",
    "print(f\"Adjusted F1 Score: {f1_score_adjusted:.2f}\")\n",
    "print(\"Adjusted Confusion Matrix:\")\n",
    "print(confusion_matrix_adjusted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/47k8q3q1449cq8kwzkz5r8ch0000gr/T/ipykernel_37379/2673877449.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_with_labels['predictions'][:len(y_pred)] = y_pred  # Assign predictions to the corresponding length\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.close('all')\n",
    "\n",
    "# Assuming 'data_with_labels' is your DataFrame with 'value', 'label', and 'predictions'\n",
    "data_with_labels['predictions'] = np.zeros(len(data_with_labels), dtype=int)  # Initialize with zeros\n",
    "data_with_labels['predictions'][:len(y_pred)] = y_pred  # Assign predictions to the corresponding length\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot the entire time series in blue\n",
    "plt.plot(data_with_labels.index, data_with_labels['value'], color='blue', label='Creep Data', alpha=0.5)\n",
    "\n",
    "# Highlight the actual event times in red\n",
    "actual_event_times = data_with_labels.index[data_with_labels['label'] == 1]\n",
    "plt.scatter(actual_event_times, \n",
    "            data_with_labels['value'][data_with_labels['label'] == 1],\n",
    "            color='red', label='Actual Events', marker='o', s=50)  # Use markers for visibility\n",
    "\n",
    "# Highlight the predicted event times in green\n",
    "predicted_event_times = data_with_labels.index[data_with_labels['predictions'] == 1]\n",
    "plt.scatter(predicted_event_times, \n",
    "            data_with_labels['value'][data_with_labels['predictions'] == 1],\n",
    "            color='green', label='Predicted Events', marker='o', s=50,alpha=0.5)  # Use markers for visibility\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Creep Value')\n",
    "plt.title('Time Series with Highlighted Actual and Predicted Event Times')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 1.00\n",
      "Adjusted Precision: 1.00\n",
      "Adjusted Recall: 0.99\n",
      "Adjusted F1 Score: 0.99\n",
      "Adjusted Confusion Matrix:\n",
      "[[278355     31]\n",
      " [   231  23849]]\n",
      "True Positives: 23849\n",
      "True Negatives: 278355\n",
      "False Positives: 31\n",
      "False Negatives: 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <NSViewBackingLayer: 0x7fa8ffc1ec20> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <NSViewBackingLayer: 0x7fa8ffc1ec20> contents scale of 2 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import creep_event_picker as cep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the HDF5 data\n",
    "with h5py.File('../../Data/DATA_tidied/HDF5/CWN1.h5', 'r') as hdf:\n",
    "    # Access a specific dataset\n",
    "    dataset = hdf['CWN1_10.0mins']\n",
    "    slip = dataset['Slip_CWN1_10.0mins'][:]\n",
    "    time = dataset['Time_CWN1_10.0mins'][:]\n",
    "    \n",
    "    # Decode the time data\n",
    "    decoded_time = [byte_str.decode('utf-8') for byte_str in time]\n",
    "    decoded_time = pd.to_datetime(decoded_time)\n",
    "\n",
    "    # Interpolate data\n",
    "    tm_int, creep_int, upsampled = cep.interpolate(decoded_time, slip, 10)\n",
    "    sos = scipy.signal.butter(4,[1/7200,1/120], 'band',output='sos',fs=0.10)  # bandpass filter for 2hrs and 5days\n",
    "    creep_data  = scipy.signal.sosfiltfilt(sos, creep_int)  # filter the data\n",
    "    time_series_data = pd.Series(creep_data, index=pd.to_datetime(tm_int))\n",
    "\n",
    "# Load the event catalogue\n",
    "event_catalogue = pd.read_csv('../../Data/all_creep_event_picks_new_qc_Oct_02_2024.csv', index_col=0)\n",
    "event_catalogue.drop(event_catalogue[event_catalogue['Creepmeter_abbrv'] != 'CWN1'].index, inplace=True)\n",
    "event_catalogue.drop(event_catalogue[event_catalogue['File_code'] != 'cwn_0'].index, inplace=True)\n",
    "event_catalogue.reset_index(inplace=True, drop=True)\n",
    "event_catalogue['start_time'] = pd.to_datetime(event_catalogue['ST'])\n",
    "event_catalogue['end_time'] = pd.to_datetime(event_catalogue['ET'])\n",
    "\n",
    "# Initialize a labels array with zeros\n",
    "labels = np.zeros(len(time_series_data), dtype=int)\n",
    "\n",
    "# Label the data based on event start and end times\n",
    "for _, row in event_catalogue.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    \n",
    "    # Find the start index for the event\n",
    "    start_index = time_series_data.index.searchsorted(start_time, side='left')\n",
    "    # Find the end index for the event (add one to include the last point in the event)\n",
    "    end_index = time_series_data.index.searchsorted(end_time, side='right') - 1\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    start_index = min(start_index, len(time_series_data) - 1)\n",
    "    end_index = min(end_index, len(time_series_data) - 1)\n",
    "    \n",
    "    # Label the range between start and end indices\n",
    "    if start_index <= end_index:\n",
    "        labels[start_index:end_index + 1] = 1  # +1 to include the end index\n",
    "\n",
    "# Combine into a DataFrame if needed\n",
    "data_with_labels = pd.DataFrame({\n",
    "    'value': time_series_data,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "def extract_features(time_series, labels, window_size):\n",
    "    features = []\n",
    "    extracted_labels = []\n",
    "\n",
    "    # Iterate through the time series data using a sliding window\n",
    "    for i in range(len(time_series) - window_size + 1):\n",
    "        window = time_series[i:i + window_size]\n",
    "        \n",
    "        # Calculate features for the current window\n",
    "        mean = window.mean()\n",
    "        std = window.std()\n",
    "        min_val = window.min()\n",
    "        max_val = window.max()\n",
    "        median = window.median()\n",
    "        q25 = np.percentile(window, 25)\n",
    "        q75 = np.percentile(window, 75)\n",
    "        \n",
    "        features.append([mean, std, min_val, max_val, median, q25, q75])\n",
    "        \n",
    "        # Access labels using .iloc to avoid the FutureWarning\n",
    "        extracted_labels.append(labels.iloc[i + window_size - 1])  # Use the label for the last point in the window\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    features = np.array(features)\n",
    "    extracted_labels = np.array(extracted_labels)\n",
    "\n",
    "    return features, extracted_labels\n",
    "\n",
    "# Define window size\n",
    "window_size = 432  # Example: 3 days worth of data\n",
    "\n",
    "# Extract features\n",
    "X, y = extract_features(data_with_labels['value'], data_with_labels['label'], window_size)\n",
    "\n",
    "# Optionally, standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Combine features and labels into a DataFrame\n",
    "features_df = pd.DataFrame(X_scaled, columns=['mean', 'std', 'min', 'max', 'median', 'q25', 'q75'])\n",
    "features_df['label'] = y\n",
    "\n",
    "# Step 2.4: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Step 3.5: Train a Random Forest Model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust the threshold\n",
    "threshold = 0.7  # Change this value to your desired threshold\n",
    "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "accuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\n",
    "precision_adjusted = precision_score(y_test, y_pred_adjusted)\n",
    "recall_adjusted = recall_score(y_test, y_pred_adjusted)\n",
    "f1_score_adjusted = f1_score(y_test, y_pred_adjusted)\n",
    "confusion_matrix_adjusted = confusion_matrix(y_test, y_pred_adjusted)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Adjusted Accuracy: {accuracy_adjusted:.2f}\")\n",
    "print(f\"Adjusted Precision: {precision_adjusted:.2f}\")\n",
    "print(f\"Adjusted Recall: {recall_adjusted:.2f}\")\n",
    "print(f\"Adjusted F1 Score: {f1_score_adjusted:.2f}\")\n",
    "print(\"Adjusted Confusion Matrix:\")\n",
    "print(confusion_matrix_adjusted)\n",
    "\n",
    "# Analyze the confusion matrix\n",
    "TP = confusion_matrix_adjusted[1, 1]  # True Positives\n",
    "TN = confusion_matrix_adjusted[0, 0]  # True Negatives\n",
    "FP = confusion_matrix_adjusted[0, 1]  # False Positives\n",
    "FN = confusion_matrix_adjusted[1, 0]  # False Negatives\n",
    "\n",
    "print(f\"True Positives: {TP}\")\n",
    "print(f\"True Negatives: {TN}\")\n",
    "print(f\"False Positives: {FP}\")\n",
    "print(f\"False Negatives: {FN}\")\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_adjusted, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Event', 'Event'], yticklabels=['No Event', 'Event'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Adjusted)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepmeters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
