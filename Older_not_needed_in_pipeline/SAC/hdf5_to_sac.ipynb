{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "'''import inflect\n",
    "c2h.stringify = inflect.engine()'''\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import csv_to_hdf5 as c2h\n",
    "import obspy\n",
    "import math\n",
    "import creep_event_picker as cep\n",
    "from obspy import UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../Data/DATA_tidied/HDF5/'  # Replace with your actual directory path\n",
    "files = c2h.list_files_in_directory(directory)\n",
    "print(files)\n",
    "#del files[10]\n",
    "files.sort()\n",
    "#del files[1],files[25],files[25],files[25],files[25],files[25],files[25],files[25],files[29],files[37],files[42],files[45],files[45],files[53],files[53],files[54]\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = ['SH30.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict = {\n",
    "        1/60: '1S',    # 1 second\n",
    "        1/6: '10S',  # 10 seconds\n",
    "        1/2: '30S',  # 30 seconds\n",
    "        1: '1T',  # 1 minute\n",
    "        2: '2T',  # 2 minutes\n",
    "        5: '5T',  # 5 minutes\n",
    "        10: '10T',# 10 minutes\n",
    "        15: '15T', # 15 minutes\n",
    "        30: '30T',# 30 minutes\n",
    "        60: '60T'    # 60 minutes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def interpolate(time,slip, freq):\n",
    "    creeping_df = pd.DataFrame({'Time':time,'Tm':time,'Slip':slip})\n",
    "    creeping_df.Time = creeping_df.Time.dt.round(freq) #round creep times to nearest mins (make evenly spaced)\n",
    "    creeping_df.Tm = creeping_df.Tm.dt.round(freq)\n",
    "    creeping_df.set_index('Time',inplace=True) #set index of the dataframe\n",
    "    creeping_df.drop_duplicates(subset=['Tm'], inplace=True) \n",
    "    upsampled = creeping_df.resample(freq).ffill(1)\n",
    "    return upsampled'''\n",
    "\n",
    "def interpolate(time, slip, freq):\n",
    "    creeping_df = pd.DataFrame({'Time': time, 'Slip': slip})\n",
    "    creeping_df['Time'] = creeping_df['Time'].dt.round(freq)\n",
    "    creeping_df.set_index('Time', inplace=True)\n",
    "\n",
    "    creeping_df = creeping_df.groupby(creeping_df.index).mean()\n",
    "\n",
    "    # Forward-fill gaps\n",
    "    upsampled = creeping_df.resample(freq).ffill(limit=1)  # optional: limit=1 prevents long fills\n",
    "    upsampled['Tm'] = upsampled.index  # if needed downstream\n",
    "    return upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creepmeter_dataframe_SAC = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''try:\n",
    "    Creepmeter_dataframe_SAC = pd.read_csv('../../Data/DATA_tidied/creepmeter_metadata_post_standardisation_sac_codes.csv',index_col=0)\n",
    "except FileNotFoundError:\n",
    "    Creepmeter_dataframe_SAC = pd.DataFrame()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creepmeter_dataframe_SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    abbreviation = files[i][:4]\n",
    "    if abbreviation[2]=='.':\n",
    "        abbreviation = abbreviation[:2]\n",
    "    print(abbreviation,i)\n",
    "    try:\n",
    "        # Open the HDF5 file in read mode\n",
    "        with h5py.File('../../Data/DATA_tidied/HDF5/{k}.h5'.format(k=abbreviation), 'r') as f:\n",
    "            try:\n",
    "                author = f.attrs['author']\n",
    "            except KeyError:\n",
    "                print('no author')\n",
    "            network = f.attrs['network']\n",
    "            print(network)\n",
    "            latitude = f.attrs['latitude']\n",
    "            longitude = f.attrs['longitude']\n",
    "            depth = f.attrs['depth']\n",
    "            length = f.attrs['length'] \n",
    "            obliquity = f.attrs['obliquity']\n",
    "            # Loop through each key in the file\n",
    "            keys = list(f.keys())\n",
    "            print(keys)\n",
    "            \n",
    "            for key in f.keys():\n",
    "                if key not in ['Temperature','Temperature_1T','Temperature_5T','Daily_measurements','Manual_measurements','Orthogonal']:\n",
    "                    print(\"Key:\", key)\n",
    "                    data = f[key]  # Access the dataset\n",
    "                    data_keys = list(data.keys())\n",
    "                    print(data_keys)\n",
    "                    slip = data[data_keys[0]][:]\n",
    "                    time =  data[data_keys[1]][:]\n",
    "                    decoded_time = [byte_str.decode('utf-8') for byte_str in time]\n",
    "                    decoded_time = pd.to_datetime(decoded_time)\n",
    "\n",
    "                    smpl_rate = data.attrs['sampling_rate']   \n",
    "                    time_units = data.attrs['time_units']     \n",
    "                    slip_units = data.attrs['slip_units']  \n",
    "                    channel = data.attrs['channel'] \n",
    "                    starttime = data.attrs['starttime'] \n",
    "                    delta = data.attrs['delta']\n",
    "                    freq_chosen = frequency_dict[smpl_rate]\n",
    "                    upsampled = interpolate(decoded_time,slip,freq_chosen)\n",
    "                    print(\"Interpolated Slip length:\", len(upsampled['Slip']))\n",
    "                    print(\"Interpolated Time range:\", upsampled['Tm'].min(), \"to\", upsampled['Tm'].max())\n",
    "                    plt.figure()\n",
    "                    plt.plot(upsampled['Tm'], upsampled['Slip'])\n",
    "                    plt.title(\"Before SAC Write: {k}\".format(k=files[i]))\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                    tr = obspy.Trace(np.array(upsampled['Slip']))\n",
    "                    st = obspy.Stream(tr)\n",
    "                    st[0].stats.network = network\n",
    "                    st[0].stats.station = abbreviation\n",
    "                    st[0].stats.location = '00'\n",
    "                    st[0].stats.channel = channel\n",
    "                    st[0].stats.starttime = starttime\n",
    "                    st[0].stats.delta = delta\n",
    "                    st[0].stats['latitude'] = latitude\n",
    "                    st[0].stats['longitude'] = longitude\n",
    "                    st[0].stats['length'] = length\n",
    "                    st[0].stats['depth'] = depth\n",
    "                    st[0].stats['obliquity'] = obliquity\n",
    "                    file_code = abbreviation + '_{k}'.format(k=freq_chosen)\n",
    "                    print(\"Trace length:\", len(tr.data), \"Upsampled Slip length:\", len(upsampled['Slip']))\n",
    "                    print(file_code)\n",
    "                    print(st[0].stats.endtime)\n",
    "                    tr.plot();\n",
    "                    instrument = pd.DataFrame({'Network':[st[0].stats.network],'Creepmeter_abbrv':['{k}'.format(k=abbreviation)],'File_code':[file_code],\n",
    "                                                'Start Time':[st[0].stats.starttime],'End Time':[st[0].stats.endtime],'Sampling rate, Hz':[st[0].stats.sampling_rate],\n",
    "                                                'Sampling rate, mins':[freq_chosen],'Latitude':[latitude],'Longitude':[longitude],'Length':[length],'Depth':[depth],\n",
    "                                                'Obliquity':[obliquity]})\n",
    "                    \n",
    "                    Creepmeter_dataframe_SAC = pd.concat([Creepmeter_dataframe_SAC,instrument],ignore_index=True)\n",
    "                    \n",
    "                    Creepmeter_dataframe_SAC.drop_duplicates(subset='File_code',inplace=True)\n",
    "                    Creepmeter_dataframe_SAC.reset_index(inplace=True,drop=True)\n",
    "                    \n",
    "                    #Creepmeter_dataframe_SAC.to_csv('../../Data/DATA_tidied/creepmeter_metadata_post_standardisation_sac_codes.csv')\n",
    "                    #st.write('../../Data/DATA_tidied/SAC/{k}.SAC'.format(k=file_code),format='SAC')\n",
    "    except:\n",
    "        print('no file found')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepmeter_list = pd.read_excel('../../Data/Creepmeter_list.xlsx')\n",
    "creepmeter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = []\n",
    "for i in range(len(Creepmeter_dataframe_SAC)):\n",
    "    abbrv = Creepmeter_dataframe_SAC['Creepmeter_abbrv'].iloc[i]\n",
    "    print(abbrv)\n",
    "    instrument_df = creepmeter_list[creepmeter_list['Creepmeter_abbrv'] == abbrv]\n",
    "    full_name.append(instrument_df['Creepmeter_full_name'].iloc[0])\n",
    "\n",
    "print(full_name)\n",
    "Creepmeter_dataframe_SAC['Creepmeter_full_name'] = full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creepmeter_dataframe_SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Creepmeter_dataframe_SAC.to_csv('../../Data/DATA_tidied/creepmeter_metadata_post_standardisation_sac_codes_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = obspy.read('../../Data/DATA_tidied/SAC/DU30_1T.SAC')\n",
    "st[0].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../../Data/DATA_tidied/HDF5/SIV1.h5', 'r+') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(keys)\n",
    "    old_group_name = 'SIV1_0.16667mins'\n",
    "    new_group_name = 'SIV1_10s'\n",
    "    old_dataset_name1 = 'Slip_SIV1_0.16667mins'\n",
    "    new_dataset_name1 = 'Slip_SIV1_10s'\n",
    "    old_dataset_name2 = 'Time_SIV1_0.16667mins'\n",
    "    new_dataset_name2 = 'Time_SIV1_10s'\n",
    "     # Check if the old group and dataset exist\n",
    "    if old_group_name in f:\n",
    "        # Create a new group\n",
    "        new_group = f.create_group(new_group_name)\n",
    "        #new_group = f[new_group_name]\n",
    "\n",
    "        new_group.attrs['sampling_rate'] = f[old_group_name].attrs['sampling_rate']  # Example: 100 Hz sampling rate (10 ms interval)\n",
    "        new_group.attrs['time_units'] = 'minutes'     # Time units\n",
    "        new_group.attrs['slip_units'] = 'millimetres'  # Dependent variable units (e.g., for slip)\n",
    "        new_group.attrs['channel'] = 'slip'\n",
    "        new_group.attrs['starttime'] = f[old_group_name].attrs['starttime']\n",
    "        new_group.attrs['delta'] = f[old_group_name].attrs['delta']\n",
    "        # Copy the dataset from the old group to the new group\n",
    "        if old_dataset_name1 in f[old_group_name]:\n",
    "            data = f[old_group_name][old_dataset_name1][:]\n",
    "            new_group.create_dataset(new_dataset_name1, data=data)\n",
    "\n",
    "        \n",
    "        # Copy the dataset from the old group to the new group\n",
    "        if old_dataset_name2 in f[old_group_name]:\n",
    "            data = f[old_group_name][old_dataset_name2][:]\n",
    "            new_group.create_dataset(new_dataset_name2, data=data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../../Data/DATA_tidied/HDF5/SIV1.h5', 'r+') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(keys)\n",
    "    del f['SIV1_0.16667mins']\n",
    "    keys = list(f.keys())\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../../Data/DATA_tidied/HDF5/FXC1.h5', 'r+') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(keys)\n",
    "    old_group_name = 'FXC1_1.0mins'\n",
    "    new_group_name = 'FCR1_1.0mins'\n",
    "    old_dataset_name1 = 'Slip_FXC1_1.0mins'\n",
    "    new_dataset_name1 = 'Slip_FCR1_1.0mins'\n",
    "    old_dataset_name2 = 'Time_FXC1_1.0mins'\n",
    "    new_dataset_name2 = 'Time_FCR1_1.0mins'\n",
    "     # Check if the old group and dataset exist\n",
    "    if old_group_name in f:\n",
    "        # Create a new group\n",
    "        new_group = f.create_group(new_group_name)\n",
    "        #new_group = f[new_group_name]\n",
    "\n",
    "        new_group.attrs['sampling_rate'] = f[old_group_name].attrs['sampling_rate']  # Example: 100 Hz sampling rate (10 ms interval)\n",
    "        new_group.attrs['time_units'] = 'minutes'     # Time units\n",
    "        new_group.attrs['slip_units'] = 'millimetres'  # Dependent variable units (e.g., for slip)\n",
    "        new_group.attrs['channel'] = 'slip'\n",
    "        new_group.attrs['starttime'] = f[old_group_name].attrs['starttime']\n",
    "        new_group.attrs['delta'] = f[old_group_name].attrs['delta']\n",
    "        # Copy the dataset from the old group to the new group\n",
    "        if old_dataset_name1 in f[old_group_name]:\n",
    "            data = f[old_group_name][old_dataset_name1][:]\n",
    "            new_group.create_dataset(new_dataset_name1, data=data)\n",
    "\n",
    "        \n",
    "        # Copy the dataset from the old group to the new group\n",
    "        if old_dataset_name2 in f[old_group_name]:\n",
    "            data = f[old_group_name][old_dataset_name2][:]\n",
    "            new_group.create_dataset(new_dataset_name2, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../../Data/DATA_tidied/HDF5/FCR1.h5', 'r+') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(keys)\n",
    "    del f['FXC1_1.0mins']\n",
    "    keys = list(f.keys())\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "with h5py.File('../../Data/DATA_tidied/HDF5/SC30.h5', 'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    print(keys)\n",
    "    plt.figure()\n",
    "    for key in f.keys():\n",
    "        if key not in ['Temperature','Temperature_1T','Temperature_5T','Daily_measurements','Manual_measurements','Orthogonal']:\n",
    "            print(\"Key:\", key)\n",
    "            data = f[key]  # Access the dataset\n",
    "            data_keys = list(data.keys())\n",
    "            print(data_keys)\n",
    "            slip = data[data_keys[0]][:]\n",
    "            time =  data[data_keys[1]][:]\n",
    "            decoded_time = [byte_str.decode('utf-8') for byte_str in time]\n",
    "            decoded_time = pd.to_datetime(decoded_time)\n",
    "\n",
    "            smpl_rate = data.attrs['sampling_rate']   \n",
    "            time_units = data.attrs['time_units']     \n",
    "            slip_units = data.attrs['slip_units']  \n",
    "            channel = data.attrs['channel'] \n",
    "            starttime = data.attrs['starttime'] \n",
    "            delta = data.attrs['delta']\n",
    "            freq_chosen = frequency_dict[smpl_rate]\n",
    "\n",
    "            #plt.plot(decoded_time,slip)\n",
    "            upsampled = interpolate(decoded_time,slip,freq_chosen)\n",
    "            \n",
    "            plt.plot(upsampled['Tm'],upsampled['Slip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepmeters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
